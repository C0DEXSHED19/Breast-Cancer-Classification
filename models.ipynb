{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer prediction:\n",
    "The dataset is huge so we are aiming to preprocess it before training it on models\n",
    "We will start by importing some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read data and check missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data and checking number of missing values and duplicate rows\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(data.head())\n",
    "print(\"\\nData Shape: \", data.shape)\n",
    "\n",
    "print(\"\\nNumber of duplicated rows: \", data.duplicated().sum())\n",
    "\n",
    "print(\"\\nNumber of Missing Values per column: \", data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Drop the unnecessary columns and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling out the one record with the missing cause of death\n",
    "data.loc[data['patient_id'] == 5130, 'death_from_cancer'] = 'Died of Disease'\n",
    "\n",
    "#Dropping irrelevant columns\n",
    "data = data.drop(columns=[\"er_status_measured_by_ihc\", \"radio_therapy\", \"primary_tumor_laterality\", \"chemotherapy\", \"patient_id\", \"3-gene_classifier_subtype\", \"cohort\"])\n",
    "\n",
    "#Dropping outliers\n",
    "data.drop(data[data['pam50_+_claudin-low_subtype'] == 'NC'].index, inplace=True)\n",
    "data.drop(data[data['tumor_stage'] == '0'].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Complete the missing records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Completing the missing **tumor_size** records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing 'tumor_size' values\n",
    "temp_data = data.dropna(subset=['tumor_size'])\n",
    "\n",
    "# Grouping the data by 'cancer_type' and 'pam50_+_claudin-low_subtype' on 'tumor_size'\n",
    "grouped = temp_data.groupby(['cancer_type', 'pam50_+_claudin-low_subtype'])['tumor_size']\n",
    "\n",
    "# Calculating the mean tumor size for each group\n",
    "avg_tumor_size = grouped.mean()\n",
    "\n",
    "# Filling the missing values in the original dataframe with the average of the respective type x subtype combination\n",
    "data.loc[data['tumor_size'].isna(), 'tumor_size'] = data.loc[data['tumor_size'].isna(), ['cancer_type', 'pam50_+_claudin-low_subtype']].apply(lambda x: avg_tumor_size[x['cancer_type'], x['pam50_+_claudin-low_subtype']], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Completing the missing **neoplasm_histologic_grade** records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows where 'neoplasm_histologic_grade' is missing\n",
    "grade_pred = data[data['neoplasm_histologic_grade'].isna()]\n",
    "\n",
    "# Select relevant columns\n",
    "Stage = data[[\"nottingham_prognostic_index\", \"neoplasm_histologic_grade\", \"tumor_size\", \"lymph_nodes_examined_positive\"]]\n",
    "\n",
    "# Drop rows with missing values\n",
    "Stage = Stage.dropna()\n",
    "\n",
    "# Reset index\n",
    "Stage = Stage.reset_index(drop=True)\n",
    "\n",
    "# Calculate the lymph node stage\n",
    "conditions = [\n",
    "    (Stage['lymph_nodes_examined_positive'] == 0) | ((Stage['lymph_nodes_examined_positive'] > 0) & (Stage['tumor_size'] <= 20)),\n",
    "    (Stage['lymph_nodes_examined_positive'].between(1, 3, inclusive='both')) | ((Stage['lymph_nodes_examined_positive'] > 0) & (Stage['tumor_size'].between(20, 200, inclusive='both'))),\n",
    "    Stage['lymph_nodes_examined_positive'].between(4, 9, inclusive='both'),\n",
    "    Stage['lymph_nodes_examined_positive'] >= 10\n",
    "]\n",
    "choices = [1, 2, 3, 4]\n",
    "Stage['lymph_node_stage'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "# Calculate the histological grade from the NPI\n",
    "Stage['histological_grade'] = (Stage['nottingham_prognostic_index'] - (Stage['tumor_size'] * 0.2) - Stage['lymph_node_stage'])\n",
    "\n",
    "# Ensure the histological grade is at least 1\n",
    "Stage['histological_grade'] = Stage['histological_grade'].apply(lambda x: max(1, int(x)))\n",
    "\n",
    "# Align the indices of the original DataFrame and the Stage DataFrame\n",
    "Stage = Stage.reindex(data.index)\n",
    "\n",
    "# Impute missing grades in the original DataFrame\n",
    "data.loc[data['neoplasm_histologic_grade'].isna(), 'neoplasm_histologic_grade'] = Stage.loc[grade_pred.index, 'histological_grade'].fillna(1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Completing the missing **tumor_stage** records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are building a decision tree classifier to predict the missing values in the tumor_stage column which has arounf 395 missing values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tumor_stage_pred = data[data['tumor_stage'].isnull()]       #taking the rows that contains null value for tumor_stage\n",
    "tumor_stage_pred.reset_index(inplace=True)                  #resetting index\n",
    "tumor_stage_pred = tumor_stage_pred.dropna(subset=[\"tumor_size\"])\n",
    "tumor_stage_pred = tumor_stage_pred.dropna(subset=[\"lymph_nodes_examined_positive\"])\n",
    "tumor_stage_pred = tumor_stage_pred.dropna(subset=[\"neoplasm_histologic_grade\"])\n",
    "tumor_stage_pred.reset_index(inplace=True)\n",
    "\n",
    "Stage = data[[\"tumor_size\",\"tumor_stage\",\"lymph_nodes_examined_positive\",\"neoplasm_histologic_grade\"]]  #to predict tumor stage we will use 3 features\n",
    "Stage.dropna(inplace=True)\n",
    "Stage.reset_index(inplace=True)\n",
    "x = Stage.drop(columns=\"tumor_stage\")   #features\n",
    "x = pd.get_dummies(x)\n",
    "x = x.drop(columns=\"index\")\n",
    "y = Stage[\"tumor_stage\"]                #label which is tumor_stage\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, shuffle = True)\n",
    "\n",
    "#We will run gridsearch to find the best combination of hyperparameters\n",
    "param_grid = {'max_depth':[2,5,10,20],\n",
    "              'min_samples_split':[5,10,15],\n",
    "              'criterion':['gini','entropy','log_loss']}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best tree Hyperparameters:\", best_params)\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Cross-Validation Score:\", best_score)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "def plot_learning_curves(model, x, y):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model, x, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, val_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting training vs cross validation curves\n",
    "plot_learning_curves(grid_search, x_train, y_train)\n",
    "\n",
    "#Best classifier to predict tumor_stage\n",
    "print(\"\\n\",best_model)\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Tumor stage Predictor's accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the accuracy and the score of the model through different metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tumor_f1 = f1_score(y_test, y_pred, average = None)    #F1 for every class\n",
    "print(\"\\nTest tumor F1_score:\", tumor_f1)\n",
    "tumor_recall = recall_score(y_test, y_pred, average = None) #recall for every class\n",
    "print(\"\\nTest tumor Recall:\", tumor_recall)\n",
    "tumor_precision = precision_score(y_test, y_pred, average = None)   #precision for every class\n",
    "print(\"\\nTest tumor Precision:\", tumor_precision)\n",
    "\n",
    "print(\"\\nTest tumor confusion matrix:\", confusion_matrix(y_test, y_pred))   #confusion matrix\n",
    "\n",
    "print(\"\\nTest tumor classification report: \", classification_report(y_test, y_pred, target_names=[\"1\", \"2\", \"3\"]))  #report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we will use our classifier to predct the missing values for all the rows in the dataset that had an empty tumor_stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the null values of tumor stage with model predictions\n",
    "X_tumor_test = tumor_stage_pred[[\"tumor_size\",\"lymph_nodes_examined_positive\",\"neoplasm_histologic_grade\"]]\n",
    "\n",
    "X_tumor_test.dropna(inplace=True)\n",
    "#print(\"\\nmissing values after: \", X_tumor_test.isna().sum())\n",
    "y_pred = best_model.predict(X_tumor_test)    #getting the predictions on the test data which we extracted from the dataset (test data is all rows that had null values for tumor_stage\n",
    "\n",
    "tumor_stage_pred[\"tumor_stage\"] = y_pred     #filling the values of tumor_stage with our predicted values\n",
    "\n",
    "\n",
    "data = data.dropna(subset=[\"tumor_stage\"])\n",
    "\n",
    "data = pd.concat([data, tumor_stage_pred], ignore_index=False, sort=False)\n",
    "print(\"Data shape: \", data.shape, \"\\nData: \",data.head())\n",
    "print(data[\"tumor_stage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary column and checking number of missing values after predicting tumor_stage column\n",
    "data = data.drop(columns=[\"level_0\",\"index\"])\n",
    "print(data.shape)\n",
    "print(\"\\nmissing values: \", data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding categorical features and then filling null values with means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Label Encoder to encode categorical features in the data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical = data.select_dtypes(exclude=\"number\")\n",
    "categorical = categorical.drop(columns=\"cancer_type\")\n",
    "\n",
    "\n",
    "data = data.drop(columns=categorical)\n",
    "\n",
    "categorical = categorical.astype(str)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "categorical = categorical.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "data = pd.concat([data,categorical], axis=1)\n",
    "print(\"full dataset with encoded values :\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values with means\n",
    "print(data.isna().sum().sum())\n",
    "label = data[\"cancer_type\"]\n",
    "data = data.drop(columns=\"cancer_type\")\n",
    "print(data)\n",
    "mean = data.mean()\n",
    "data.fillna(mean, inplace=True)\n",
    "print(data.shape)\n",
    "print(data.isna().sum().sum())\n",
    "data = pd.concat([label,data], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Checking number of missing values\n",
    "print(data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data with z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "label = data[\"cancer_type\"]\n",
    "data = data.drop(columns=\"cancer_type\")\n",
    "data_z_scaled = data.copy() \n",
    "  \n",
    "#looping through every column to normalize with z-score\n",
    "for column in data_z_scaled.columns: \n",
    "    data_z_scaled[column] = (data_z_scaled[column] - data_z_scaled[column].mean()) / data_z_scaled[column].std()  \n",
    "    \n",
    "\n",
    "data = pd.concat([label,data_z_scaled], axis=1)\n",
    "data = data.fillna(0)        #because one column has only 0 values when computing the z score we got an undefined result and led to a lot of NAN.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data (70-30)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[\"cancer_type\"]\n",
    "x = data.drop(columns=\"cancer_type\")\n",
    "\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size = 0.3, random_state=3, shuffle = True)\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size = 0.1, random_state=3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Oversampling Or Undersampling since dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([x_train_val,y_train_val], axis=1)\n",
    "temp1 = pd.concat([x_test,y_test], axis=1)\n",
    "def oversample(df):\n",
    "    classes = {\"Breast Mixed Ductal and Lobular Carcinoma\":len(df[df['cancer_type'].str.contains('Breast Mixed Ductal and Lobular Carcinoma')]),\"Breast Invasive Ductal Carcinoma\":len(df[df['cancer_type'].str.contains('Breast Invasive Ductal Carcinoma')]), \"Breast Invasive Lobular Carcinoma\":len(df[df['cancer_type'].str.contains('Breast Invasive Lobular Carcinoma')]), \"Breast Invasive Mixed Mucinous Carcinoma\":len(df[df['cancer_type'].str.contains('Breast Invasive Mixed Mucinous Carcinoma')])}\n",
    "    most = max(classes.values())\n",
    "    classes_list = []\n",
    "    for key in classes:\n",
    "        classes_list.append(df[df['cancer_type'] == key]) \n",
    "    classes_sample = []\n",
    "    for i in range(1,len(classes_list)):\n",
    "        classes_sample.append(classes_list[i].sample(most, replace=True))\n",
    "    df_maybe = pd.concat(classes_sample)\n",
    "    final_df = pd.concat([df_maybe,classes_list[0]], axis=0)\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    return final_df\n",
    "\n",
    "temp = oversample(temp)\n",
    "temp1 = oversample(temp1)\n",
    "y_train_val = temp[\"cancer_type\"]\n",
    "x_train_val = temp.drop(columns=\"cancer_type\")\n",
    "y_test = temp1[\"cancer_type\"]\n",
    "x_test = temp1.drop(columns=\"cancer_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train_val, y_train_val = ros.fit_resample(x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=\"not minority\",random_state=42)\n",
    "x_train_val, y_train_val = rus.fit_resample(x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training different models and tuning the hyperparameters with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#!pip install keras.wrappers\n",
    "#!pip install tensorflow\n",
    "#!pip install scikeras\n",
    "#!pip install keras==2.15.0\n",
    "#from scikeras.wrappers import KerasClassifier\n",
    "#from tensorflow import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "x_train_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_parameters = {'kernel':['linear','rbf','sigmoid','poly'],\n",
    "                  'gamma':['scale','auto'],\n",
    "                  'C': [0.1, 1, 10, 100, 1000]\n",
    "                 }\n",
    "\n",
    "svm_CLF = SVC()\n",
    "\n",
    "svm_grid_search = GridSearchCV(svm_CLF,svm_parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "svm_grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "svm_model = svm_grid_search.best_estimator_\n",
    "print(\"Best svm Model:\", svm_model)\n",
    "\n",
    "svm_best_params = svm_grid_search.best_params_\n",
    "print(\"Best svm Hyperparameters:\", svm_best_params)\n",
    "\n",
    "svm_best_score = svm_grid_search.best_score_\n",
    "print(\"Best svm Cross-Validation Score:\", svm_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot validation vs training curve\n",
    "def plot_learning_curves(model, x, y):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model, x, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, val_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(svm_model, x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 score, recall, precision and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check F1, recall, accuracy\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svm_pred = svm_model.predict(x_test)\n",
    "print(\"\\nsvm model's accuracy is : \" ,accuracy_score(y_test,svm_pred))\n",
    "\n",
    "svm_f1 = f1_score(y_test, svm_pred, average = None)\n",
    "print(\"\\nTest svm F1_score:\", svm_f1)\n",
    "svm_recall = recall_score(y_test, svm_pred, average = None)\n",
    "print(\"\\nTest svm Recall:\", svm_recall)\n",
    "svm_precision = precision_score(y_test, svm_pred, average = None)\n",
    "print(\"\\nTest svm Precision:\", svm_precision)\n",
    "\n",
    "print(\"\\nTest svm confusion matrix:\", confusion_matrix(y_test, svm_pred))\n",
    "\n",
    "print(\"\\nTest svm classification report: \", classification_report(y_test, svm_pred, target_names=[\"Breast Invasive Ductal Carcinoma\",\"Breast Mixed Ductal and Lobular Carcinoma\", \"Breast Invasive Lobular Carcinoma\",\"Breast Invasive Mixed Mucinous Carcinoma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "xgb_parameters = {'learning_rate': [0.01,0.05,0.1],\n",
    "        \n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        \n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        \n",
    "        }\n",
    "\n",
    "xgb_CLF = GradientBoostingClassifier()\n",
    "\n",
    "xgb_grid_search = GridSearchCV(xgb_CLF,xgb_parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "xgb_grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "xgb_best_model = xgb_grid_search.best_estimator_\n",
    "print(\"Best xgb Model:\", xgb_best_model)\n",
    "\n",
    "xgb_best_params = xgb_grid_search.best_params_\n",
    "print(\"Best xgb Hyperparameters:\", xgb_best_params)\n",
    "\n",
    "xgb_best_score = xgb_grid_search.best_score_\n",
    "print(\"Best xgb Cross-Validation Score:\", xgb_best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(xgb_best_model, x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1, recall, precision and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb_best_model.predict(x_test)\n",
    "print(\"\\nsvm model's accuracy is : \" ,accuracy_score(y_test,xgb_pred))\n",
    "\n",
    "xgb_f1 = f1_score(y_test, xgb_pred, average = None)\n",
    "print(\"\\nTest xgb F1_score:\", xgb_f1)\n",
    "xgb_recall = recall_score(y_test, xgb_pred, average = None)\n",
    "print(\"\\nTest xgb Recall:\", xgb_recall)\n",
    "xgb_precision = precision_score(y_test, xgb_pred, average = None)\n",
    "print(\"\\nTest xgb Precision:\", xgb_precision)\n",
    "\n",
    "print(\"\\nTest xgb confusion matrix:\", confusion_matrix(y_test, xgb_pred))\n",
    "\n",
    "print(\"\\nTest xgb classification report: \", classification_report(y_test, xgb_pred, target_names=[\"Breast Invasive Ductal Carcinoma\",\"Breast Mixed Ductal and Lobular Carcinoma\", \"Breast Invasive Lobular Carcinoma\",\"Breast Invasive Mixed Mucinous Carcinoma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_parameters = {'max_depth':[2,5,10],\n",
    "              'min_samples_split':[5,10,15],\n",
    "              'criterion':['gini','entropy','log_loss']}\n",
    "\n",
    "tree_CLF = DecisionTreeClassifier()\n",
    "\n",
    "tree_grid_search = GridSearchCV(tree_CLF,tree_parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "tree_grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "best_modeltree = tree_grid_search.best_estimator_\n",
    "print(\"Best tree Model:\", best_modeltree)\n",
    "\n",
    "best_paramstree = tree_grid_search.best_params_\n",
    "print(\"Best tree Hyperparameters:\", best_paramstree)\n",
    "\n",
    "best_scoretree = tree_grid_search.best_score_\n",
    "print(\"Best tree Cross-Validation Score:\", best_scoretree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(best_modeltree, x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = best_modeltree.predict(x_test)\n",
    "print(\"\\ntree model's accuracy is : \" ,accuracy_score(y_test,tree_pred))\n",
    "\n",
    "tree_f1 = f1_score(y_test, tree_pred, average = None)\n",
    "print(\"\\nTest tree F1_score:\", tree_f1)\n",
    "tree_recall = recall_score(y_test, tree_pred, average = None)\n",
    "print(\"\\nTest tree Recall:\", tree_recall)\n",
    "tree_precision = precision_score(y_test, tree_pred, average = None)\n",
    "print(\"\\nTest tree Precision:\", tree_precision)\n",
    "\n",
    "print(\"\\nTest tree confusion matrix:\", confusion_matrix(y_test, tree_pred))\n",
    "\n",
    "print(\"\\nTest tree classification report: \", classification_report(y_test, tree_pred, target_names=[\"Breast Invasive Ductal Carcinoma\",\"Breast Mixed Ductal and Lobular Carcinoma\", \"Breast Invasive Lobular Carcinoma\",\"Breast Invasive Mixed Mucinous Carcinoma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {'max_depth':[2,3,5,10,20],\n",
    "              'criterion':['gini','entropy','log_loss'],\n",
    "              'min_samples_split':[2,5,10],\n",
    "                 'n_estimators':[50,100,200]}\n",
    "\n",
    "rf_CLF = RandomForestClassifier()\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_CLF,rf_parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "rf_grid_search.fit(x_train_val, y_train_val)\n",
    "\n",
    "best_modelrf = rf_grid_search.best_estimator_\n",
    "print(\"Best rf Model:\", best_modelrf)\n",
    "\n",
    "best_paramsrf = rf_grid_search.best_params_\n",
    "print(\"Best rf Hyperparameters:\", best_paramsrf)\n",
    "\n",
    "best_scorerf = rf_grid_search.best_score_\n",
    "print(\"Best rf Cross-Validation Score:\", best_scorerf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(best_modelrf, x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1, recall, precision and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = best_modelrf.predict(x_test)\n",
    "print(\"\\nrf model's accuracy is : \" ,accuracy_score(y_test,rf_pred))\n",
    "\n",
    "rf_f1 = f1_score(y_test, rf_pred, average = None)\n",
    "print(\"\\nTest rf F1_score:\", rf_f1)\n",
    "rf_recall = recall_score(y_test, rf_pred, average = None)\n",
    "print(\"\\nTest rf Recall:\", rf_recall)\n",
    "rf_precision = precision_score(y_test, rf_pred, average = None)\n",
    "print(\"\\nTest rf Precision:\", rf_precision)\n",
    "\n",
    "print(\"\\nTest rf confusion matrix:\", confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "print(\"\\nTest rf classification report: \", classification_report(y_test, rf_pred, target_names=[\"Breast Invasive Ductal Carcinoma\",\"Breast Mixed Ductal and Lobular Carcinoma\", \"Breast Invasive Lobular Carcinoma\",\"Breast Invasive Mixed Mucinous Carcinoma\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
